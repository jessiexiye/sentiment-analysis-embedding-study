{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"colab":{"name":"Bidirectional_LSTM_Sentiment_Classification.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"v1Q-bpwRKBon","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592736039708,"user_tz":-480,"elapsed":649,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchtext import data\n","from torchtext.data import Field, LabelField, BucketIterator\n","\n","import spacy\n","import numpy as np\n","\n","import random\n","import math\n","import time\n","\n","SEED = 1234\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","# # load the spacy model for English\n","# spacy_en = spacy.load('en_core_web_sm')\n","\n","# # tokenizer function, can be passed to TorchText \n","# def tokenize_en(text):\n","#     \"\"\"\n","#     Tokenizes English text from a string into a list of tokens\n","#     \"\"\"\n","#     return [tok.text for tok in spacy_en.tokenizer(text)]"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"30CmdjLUKkXk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592736064493,"user_tz":-480,"elapsed":746,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}},"outputId":"477fe68a-a1e7-4779-eaa4-644e4e3942a0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nxbxl4XhKBor","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1592736070567,"user_tz":-480,"elapsed":2734,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}},"outputId":"99fe924b-ba99-43b5-9c0a-483a51838357"},"source":["TEXT = Field(tokenize = 'spacy',\n","             include_lengths = True)\n","\n","# LABEL = Field(sequential = False,\n","#               pad_token = None,\n","#               unk_token = None,\n","#               dtype = float)\n","\n","LABEL = LabelField(dtype=torch.float)\n","\n","train_data, valid_data, test_data = data.TabularDataset.splits(path = '/content/drive/My Drive/Colab Notebooks/NLP/', train = 'sst_train.csv',\n","                                        validation = 'sst_dev.csv', test = 'sst_test.csv',\n","                                        format = 'csv', fields=[(\"idx\", None), (\"text\", TEXT), (\"label\", LABEL)],\n","                                        skip_header = True)\n","TEXT.build_vocab(train_data, min_freq = 1)\n","LABEL.build_vocab(train_data)\n","print(\"Unique tokens in TEXT vocabulary: \" + str(len(TEXT.vocab)))\n","print(\"Unique tokens in LABEL vocabulary: \" + str(len(LABEL.vocab)))\n","print(\"LABEL vocabulary frequency: \" + str(LABEL.vocab.freqs))\n","\n","print(vars(train_data.examples[0]))\n","\n","print(\"Number of training examples: \" + str(len(train_data)))\n","print(\"Number of validation examples: \" + str(len(valid_data)))\n","print(\"Number of testing examples: \" + str(len(test_data)))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Unique tokens in TEXT vocabulary: 13824\n","Unique tokens in LABEL vocabulary: 2\n","LABEL vocabulary frequency: Counter({'1': 3610, '0': 3310})\n","{'text': ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', 's', 'new', 'conan', 'and', 'that', 'he', 's', 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', 'jean', 'claud', 'van', 'damme', 'or', 'steven', 'segal'], 'label': '1'}\n","Number of training examples: 6920\n","Number of validation examples: 872\n","Number of testing examples: 1821\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vNmZsIqFKBo5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592736072676,"user_tz":-480,"elapsed":832,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}}},"source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE,\n","    sort_within_batch = True,\n","    sort_key = lambda x: len(x.text),\n","    device = device)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-TJteFeKBo7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592736073793,"user_tz":-480,"elapsed":505,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}}},"source":["import torch.nn as nn\n","\n","class RNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n","                 bidirectional, dropout, pad_idx):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n","        \n","        self.rnn = nn.LSTM(embedding_dim, \n","                           hidden_dim, \n","                           num_layers=n_layers, \n","                           bidirectional=bidirectional, \n","                           dropout=dropout)\n","        \n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text, text_lengths):\n","        \n","        #text = [sent len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(text))\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        #pack sequence\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n","        \n","        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n","        \n","        #unpack sequence\n","        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n","        \n","        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","                \n","        #hidden = [batch size, hid dim * num directions]\n","            \n","        return self.fc(hidden)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycs8dhVvKBo_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592736074781,"user_tz":-480,"elapsed":696,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}}},"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","# CONTEXT_DIM = 100\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = RNN(INPUT_DIM, \n","            EMBEDDING_DIM, \n","            HIDDEN_DIM, \n","            OUTPUT_DIM, \n","            N_LAYERS, \n","            BIDIRECTIONAL, \n","            DROPOUT, \n","            PAD_IDX)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"3tt7Wa4EKBpB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592736075700,"user_tz":-480,"elapsed":829,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}},"outputId":"4c537db0-6ed1-4a80-a435-84ef735afca4"},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print('The model has ' + str(count_parameters(model)) + ' trainable parameters')"],"execution_count":24,"outputs":[{"output_type":"stream","text":["The model has 3693057 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pfeypjovKBpF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592736076763,"user_tz":-480,"elapsed":509,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}}},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NJcWoBwKBpJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592736078703,"user_tz":-480,"elapsed":705,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}}},"source":["criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgHxa6kvKBpM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592736079006,"user_tz":-480,"elapsed":460,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}}},"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"_lb5JBG7KBpP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592736080599,"user_tz":-480,"elapsed":719,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}}},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        optimizer.zero_grad()\n","        \n","        text, text_lengths = batch.text\n","        \n","        predictions = model(text, text_lengths).squeeze(1)\n","        \n","        loss = criterion(predictions, batch.label)\n","        \n","        acc = binary_accuracy(predictions, batch.label)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"mK3XyOkYKBpR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592736081102,"user_tz":-480,"elapsed":513,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            text, text_lengths = batch.text\n","            \n","            predictions = model(text, text_lengths).squeeze(1)\n","            \n","            loss = criterion(predictions, batch.label)\n","            \n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"WcLrBB4RKBpV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592736082820,"user_tz":-480,"elapsed":857,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}}},"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"I93rv4eYKBpX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1592736421924,"user_tz":-480,"elapsed":339434,"user":{"displayName":"Jiaxi Li","photoUrl":"","userId":"16140828207211083830"}},"outputId":"ae4fb97d-ca56-49de-e694-97ab59e7ca85"},"source":["N_EPOCHS = 5\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'bi_directional_model.pt')\n","    \n","    print(\"Epoch: \" + str(epoch+1) + \" Epoch Time: \" + str(epoch_mins) + \"m \" + str(epoch_secs) + \"s\")\n","    print(\"Train Loss: \" + str(round(train_loss, 4)) + \" Train Acc: \" + str(round(train_acc * 100, 4)))\n","    print(\"Val. Loss : \" + str(round(valid_loss, 4)) + \" Val.  Acc: \" + str(round(valid_acc * 100, 4)))\n","    print(\"Test Loss : \" + str(round(test_loss, 4)) +  \" Test  Acc: \" + str(round(test_acc * 100, 4)))\n","    print(\"\\n\")"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Epoch: 1 Epoch Time: 1m 8s\n","Train Loss: 0.6822 Train Acc: 56.1783\n","Val. Loss : 0.6583 Val.  Acc: 59.3304\n","Test Loss : 0.6647 Test  Acc: 58.0224\n","\n","\n","Epoch: 2 Epoch Time: 1m 7s\n","Train Loss: 0.654 Train Acc: 62.113\n","Val. Loss : 0.6334 Val.  Acc: 64.375\n","Test Loss : 0.6465 Test  Acc: 62.2473\n","\n","\n","Epoch: 3 Epoch Time: 1m 7s\n","Train Loss: 0.6171 Train Acc: 66.0694\n","Val. Loss : 0.5911 Val.  Acc: 67.6116\n","Test Loss : 0.6021 Test  Acc: 67.1076\n","\n","\n","Epoch: 4 Epoch Time: 1m 7s\n","Train Loss: 0.5743 Train Acc: 70.3985\n","Val. Loss : 0.589 Val.  Acc: 70.2455\n","Test Loss : 0.6134 Test  Acc: 66.6004\n","\n","\n","Epoch: 5 Epoch Time: 1m 7s\n","Train Loss: 0.5248 Train Acc: 73.5378\n","Val. Loss : 0.5832 Val.  Acc: 71.5179\n","Test Loss : 0.5904 Test  Acc: 71.6223\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ls0Yw2JWKBpa","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCh8wHrrKBpd","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}